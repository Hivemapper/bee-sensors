{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gnss_lib_py as glp\n",
    "from ubx_parser import UbxParser\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input UBX filepath\n",
    "# UBX_FILENAME = \"/Users/derekknowles/personal-data/ublox/short_test/ubx_full_messages_no_tm2.ubx\"\n",
    "# UBX_FILENAME = \"/Users/derekknowles/personal-data/ublox/short_test/ubx_full_messages_no_tm2_round_2.ubx\"\n",
    "# UBX_FILENAME = \"/Users/derekknowles/Library/CloudStorage/GoogleDrive-derek@hivemapper.com/Shared drives/bee-sensors-internal/gnss/u-blox-data/OCT2_ACTIVE_EMBARCADERO_DOWNTOWN.ubx\"\n",
    "# UBX_FILENAME = \"/Users/derekknowles/Library/CloudStorage/GoogleDrive-derek@hivemapper.com/Shared drives/bee-sensors-internal/gnss/u-blox-data/OCT2_PASSIVE_EMBARCADERO_DOWNTOWN.ubx\"\n",
    "# UBX_FILENAME = \"/Users/derekknowles/Library/CloudStorage/GoogleDrive-derek@hivemapper.com/Shared drives/bee-sensors-internal/gnss/u-blox-data/OCT2_ACTIVE_LAFAYETTE_HIGHWAYS.ubx\"\n",
    "UBX_FILENAME = \"/Users/derekknowles/Library/CloudStorage/GoogleDrive-derek@hivemapper.com/Shared drives/bee-sensors-internal/gnss/u-blox-data/OCT2_PASSIVE_LAFAYETTE_HIGHWAYS.ubx\"\n",
    "# UBX_FILENAME = \"/Users/derekknowles/Library/CloudStorage/GoogleDrive-derek@hivemapper.com/Shared drives/bee-sensors-internal/gnss/u-blox-data/OCT3_ACTIVE_PRESIDIO.ubx\"\n",
    "# UBX_FILENAME = \"/Users/derekknowles/Library/CloudStorage/GoogleDrive-derek@hivemapper.com/Shared drives/bee-sensors-internal/gnss/u-blox-data/OCT3_PASSIVE_PRESIDIO.ubx\"\n",
    "\n",
    "# whether need to parse to CSV (only needs to happen once)\n",
    "PARSE_TO_CSV = True\n",
    "\n",
    "# Scale factor to shrink large data\n",
    "# recommend 100 for files of about an hour\n",
    "SCALE_FACTOR = 100\n",
    "\n",
    "# MAXIMUM NUMBER OF SATELLITES SEEN\n",
    "MAX_NUM_SATS = 50\n",
    "\n",
    "# MAXIMUM C/N0 VALUE EXPECTED\n",
    "MAX_CN0 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARSE_TO_CSV:\n",
    "    # parse UBX file to CSV\n",
    "    UbxParser(UBX_FILENAME)\n",
    "\n",
    "dir_name = os.path.join(os.path.dirname(os.path.abspath('')),\n",
    "                                        \"results\",os.path.basename(UBX_FILENAME).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_pvt = glp.NavData(csv_path= os.path.join(dir_name, \"NAV_PVT.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = glp.gps_millis_to_datetime(min(nav_pvt[\"gps_millis\"]))\n",
    "end_time = glp.gps_millis_to_datetime(max(nav_pvt[\"gps_millis\"]))\n",
    "log_duration = end_time - start_time\n",
    "\n",
    "print(\"log start time: \", start_time)\n",
    "print(\"log end time: \", end_time)\n",
    "print(\"log duration: \", log_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot UBX PVT lat/lon solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glp.plot_map(nav_pvt, fname=os.path.join(dir_name, \"map_lat_lon.png\"), save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Number of Satellites Seen vs. Used in Position Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_sat = glp.NavData(csv_path=os.path.join(dir_name, \"NAV_SAT.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_all, all_counts = np.unique(nav_sat[\"gps_millis\"], return_counts=True)\n",
    "t0 = times_all[0]\n",
    "times_all = [(t-t0)/(1000*60) for t in times_all]\n",
    "\n",
    "# averaging window\n",
    "N = SCALE_FACTOR*10\n",
    "\n",
    "\n",
    "counts_all = glp.NavData()\n",
    "counts_all[\"time_min\"] = times_all\n",
    "counts_all[\"sats_seen\"] = all_counts\n",
    "\n",
    "counts_all_avg = glp.NavData()\n",
    "counts_all_avg[\"time_min\"] = times_all[(N//2):-(N//2)]\n",
    "counts_all_avg[\"sats_seen_avg\"] = np.convolve(all_counts, np.ones((N,))/N, mode='valid')[:-1]\n",
    "\n",
    "times_used, used_counts = np.unique(nav_sat.where(\"svUsed\",1)[\"gps_millis\"], return_counts=True)\n",
    "t0 = times_used[0]\n",
    "times_used = [(t-t0)/(1000*60) for t in times_used]\n",
    "counts_used = glp.NavData()\n",
    "counts_used[\"time_min\"] = times_used\n",
    "counts_used[\"sats_used\"] = used_counts\n",
    "\n",
    "counts_used_avg = glp.NavData()\n",
    "counts_used_avg[\"time_min\"] = times_used[(N//2):-(N//2)]\n",
    "counts_used_avg[\"sats_used_avg\"] = np.convolve(used_counts, np.ones((N,))/N, mode='valid')[:-1]\n",
    "\n",
    "fig = glp.plot_metric(counts_all,\"time_min\",\"sats_seen\",linestyle=\"None\")\n",
    "fig = glp.plot_metric(counts_all_avg,\"time_min\",\"sats_seen_avg\",markersize=0,fig=fig,linewidth=3)\n",
    "fig = glp.plot_metric(counts_used,\"time_min\",\"sats_used\",linestyle=\"None\",fig=fig)\n",
    "fig = glp.plot_metric(counts_used_avg,\"time_min\",\"sats_used_avg\",markersize=0,fig=fig,c='C5',linewidth=3)\n",
    "# fig.set_ylim(0,MAX_NUM_SATS)\n",
    "fig.axes[0].set_ylim(0,MAX_NUM_SATS)\n",
    "plt.legend([\"SVs Seen\",\"Avg SVs Seen\",\"SVs Used\",\"Avg SVs Used\"])\n",
    "\n",
    "fig.savefig(os.path.join(dir_name, \"sats_seen_vs_used.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Constellation Count Tracked from NAV-SAT messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_constellations(nav_sat, used_only=False, scale_factor=SCALE_FACTOR):\n",
    "    \"\"\" Plot stacked constellations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nav_sat : gnss_lib_py.NavData\n",
    "        DataFrame containing NAV-SAT data\n",
    "    used_only : bool\n",
    "        Whether to plot only the used satellites\n",
    "    scale_factor : int\n",
    "        Use only one timestep out of every scale_factor timesteps\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "    if used_only:\n",
    "        nav_sat = nav_sat.where(\"svUsed\",1)\n",
    "\n",
    "    all_constellations = np.unique(nav_sat[\"gnss_id\"])\n",
    "    times = []\n",
    "    unique_times = np.unique(nav_sat[\"gps_millis\"])[::scale_factor]\n",
    "\n",
    "    constellation_counts = {constellation : [] for constellation in all_constellations}\n",
    "    for idx, timestamp in enumerate(unique_times):\n",
    "        if idx % int(len(unique_times)/5.) == 0:\n",
    "            print(f\"processing {idx} of {len(unique_times)}\")\n",
    "        subset_idxs = np.argwhere(nav_sat[\"gps_millis\"] == timestamp)\n",
    "        for constellation in all_constellations:\n",
    "            constellation_counts[constellation].append(np.count_nonzero(nav_sat[\"gnss_id\",subset_idxs[:,0].tolist()] == constellation))\n",
    "\n",
    "    print(\"all done computing\")\n",
    "    t0 = unique_times[0]\n",
    "    times = [(t-t0)/(1000*60) for t in unique_times]\n",
    "    labels = [c for c in glp.GNSS_ORDER if c in all_constellations]\n",
    "    stackplot_data = [constellation_counts[c] for c in labels]\n",
    "\n",
    "\n",
    "    ax.stackplot(times, stackplot_data, labels=labels)\n",
    "\n",
    "    title = os.path.basename(UBX_FILENAME).split(\"_\")[1] + \" Antenna \"\n",
    "    if used_only:\n",
    "        title += \"Used in NAV solution\"\n",
    "    else:\n",
    "        title += \"All Sats Seen\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Number of Satellites\")\n",
    "    ax.set_xlabel(\"Time (min)\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylim(0,MAX_NUM_SATS)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_stacked_constellations(nav_sat)\n",
    "fig.savefig(os.path.join(dir_name, \"sats_sat_tracked.png\"))\n",
    "fig = plot_stacked_constellations(nav_sat, used_only=True)\n",
    "fig.savefig(os.path.join(dir_name, \"sats_sat_tracked_used.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Satellites Searched For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_sig = glp.NavData(csv_path=os.path.join(dir_name, \"NAV_SIG.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_stacked_constellations(nav_sig)\n",
    "fig.savefig(os.path.join(dir_name, \"sats_sig_searched.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot C/N0 across constellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn0_avg = (\"3)_c/n0_avg\",[])\n",
    "cn0_max = (\"1)_c/n0_max\",[])\n",
    "cn0_min = (\"4)_c/n0_mins\",[])\n",
    "cn0_top_4 = (\"2)_c/n0_top_4\",[])\n",
    "\n",
    "nav_sat_used = nav_sat.where(\"svUsed\",1)\n",
    "unique_times = np.unique(nav_sat_used[\"gps_millis\"])[::SCALE_FACTOR]\n",
    "t0 = unique_times[0]\n",
    "times = [(t-t0)/(1000*60) for t in unique_times]\n",
    "\n",
    "for idx, timestamp in enumerate(unique_times):\n",
    "    if idx % int(len(unique_times)/5.) == 0:\n",
    "        print(f\"processing {idx} of {len(unique_times)}\")\n",
    "    \n",
    "    subset = nav_sat_used.where(\"gps_millis\",timestamp)\n",
    "    cn0 = subset[\"cn0_dbhz\"]\n",
    "    cn0_avg[1].append(np.mean(cn0))\n",
    "    cn0_max[1].append(np.max(cn0))\n",
    "    cn0_min[1].append(np.min(cn0))\n",
    "    if len(subset) >= 4:\n",
    "        cn0_top_4[1].append(np.mean(np.sort(cn0)[-4:]))\n",
    "    else:\n",
    "        cn0_top_4[1].append(np.mean(cn0))\n",
    "all_cn0_data = glp.NavData()\n",
    "for metric in [cn0_max, cn0_top_4, cn0_avg, cn0_min]:\n",
    "    temp_data = glp.NavData()\n",
    "    temp_data[\"time_min\"] = times\n",
    "    temp_data[\"metric\"] = np.array([[metric[0]]*len(times)])\n",
    "    temp_data[\"cn0_dbhz\"] = metric[1]\n",
    "    all_cn0_data = glp.concat(all_cn0_data, temp_data, axis=1)\n",
    "\n",
    "fig = glp.plot_metric(all_cn0_data,\"time_min\",\"cn0_dbhz\",groupby=\"metric\",linestyle=\"None\")\n",
    "\n",
    "\n",
    "# averaging window\n",
    "N = 10\n",
    "cn0_avg_data = glp.NavData()\n",
    "cn0_avg_data[\"time_min\"] = times[(N//2):-(N//2)]\n",
    "cn0_avg_data[\"cn0_dbhz\"] = np.convolve(cn0_avg[1], np.ones((N,))/N, mode='valid')[:-1]\n",
    "fig = glp.plot_metric(cn0_avg_data,\"time_min\",\"cn0_dbhz\",\n",
    "                      markersize=0,fig=fig,c='C5',linewidth=3, label=\"Rolling Avg\")\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.ylim(0,MAX_CN0)\n",
    "\n",
    "fig.savefig(os.path.join(dir_name,\"CN0.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dop = glp.NavData(csv_path=os.path.join(dir_name, \"NAV_DOP.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = glp.plot_metric(nav_pvt,\"gps_millis\",\"hAcc\",linestyle=\"None\")\n",
    "fig.savefig(os.path.join(dir_name, \"hAcc_vs_gps_millis.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(data, threshold, title='Distribution Plot', x_label='Value'):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    # Create the CDF\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, len(x) + 1) / len(x)\n",
    "    plt.plot(x, y, label='CDF', color='C1')\n",
    "\n",
    "    # the value for which you want to calculate the percentage below\n",
    "    value = threshold\n",
    "\n",
    "    # Calculate the percentage of values below the specified value\n",
    "    percentage = np.sum(data <= value) / len(data) * 100\n",
    "\n",
    "    # Add a vertical line at the specified value\n",
    "    plt.axvline(x=value, color='C0', linestyle='--', label=f'Value: {value}')\n",
    "\n",
    "    # Add a text annotation for the percentage\n",
    "    plt.text(value, 0.8, f'   {percentage:.2f}% below {value}', color='C0')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title(title)\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = plot_distribution(nav_dop[\"hDOP\"], 4.0, title=\"hDOP Distribution\", x_label=\"hDOP\")\n",
    "fig.savefig(os.path.join(dir_name, \"hDOP_distribution.png\"))\n",
    "fig = plot_distribution(nav_dop[\"gDOP\"], 6.0, title=\"vDOP Distribution\", x_label=\"vDOP\")\n",
    "fig.savefig(os.path.join(dir_name, \"vDOP_distribution.png\"))\n",
    "fig = plot_distribution(nav_pvt[\"hAcc\"]/1000., 1.0, title=\"hAcc Distribution\", x_label=\"Horizontal Accuracy Estimate [m]\")\n",
    "fig.savefig(os.path.join(dir_name, \"hAcc_distribution.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Skyplot of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualization functions for GNSS data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "__authors__ = \"D. Knowles\"\n",
    "__date__ = \"27 Jan 2022\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from gnss_lib_py.visualizations.style import *\n",
    "from gnss_lib_py.navdata.navdata import NavData\n",
    "from gnss_lib_py.utils.coordinates import add_el_az\n",
    "\n",
    "def plot_skyplot(navdata, receiver_state,\n",
    "                 save=False, prefix=\"\", fname=None,\n",
    "                 add_sv_id_label=True, step = \"auto\", trim_options=None):\n",
    "    \"\"\"Skyplot of satellite positions relative to receiver.\n",
    "\n",
    "    First adds ``el_sv_deg`` and ``az_sv_deg`` rows to navdata if they\n",
    "    do not yet exist.\n",
    "\n",
    "    Breaks up satellites by constellation names in ``gnss_id`` and the\n",
    "    ``sv_id`` if the row is present in navdata.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    navdata : gnss_lib_py.navdata.navdata.NavData\n",
    "        Instance of the NavData class. Must include ``gps_millis`` as\n",
    "        well as satellite ECEF positions as ``x_sv_m``, ``y_sv_m``,\n",
    "        ``z_sv_m``, ``gnss_id`` and ``sv_id``.\n",
    "    receiver_state : gnss_lib_py.navdata.navdata.NavData\n",
    "        Either estimated or ground truth receiver position in ECEF frame\n",
    "        in meters as an instance of the NavData class with the\n",
    "        following rows: ``x_rx*_m``, ``y_rx*_m``, ``z_rx*_m``, ``gps_millis``.\n",
    "    save : bool\n",
    "        Saves figure if true to file specified by ``fname`` or defaults\n",
    "        to the Results folder otherwise.\n",
    "    prefix : string\n",
    "        File prefix to add to filename.\n",
    "    fname : string or path-like\n",
    "        Path to save figure to. If not None, ``fname`` is passed\n",
    "        directly to matplotlib's savefig fname parameter and prefix will\n",
    "        be overwritten.\n",
    "    add_sv_id_label : bool\n",
    "        If the ``sv_id`` row is available, will add SV ID label near the\n",
    "        satellite trail.\n",
    "    step : int or \"auto\"\n",
    "        Skyplot plotting is sped up by only plotting a portion of the\n",
    "        satellite trajectories. If default is set to \"auto\" then it will\n",
    "        plot a maximum of 50 points across each satellite trajectory. If\n",
    "        the step variable is set to a positive integer ``n`` then only\n",
    "        every nth point will be used in the trajectory. Setting the\n",
    "        steps variable to 1 will plot every satellite trajectory point\n",
    "        and may be slow to plot.\n",
    "    trim_options : None or dict\n",
    "        The ``trim_options`` variables gives control for line segments\n",
    "        being trimmed between satellite points. For example, if 24 hours\n",
    "        of a satellite is plotted, often the satellite will come in and\n",
    "        out of view and the segment between when it was lost from view\n",
    "        and when the satellite comes back in view should be trimmed.\n",
    "        If trim_options is set to the default of None, then the default\n",
    "        is set of trimming according to az_and_el and gps_millis. The\n",
    "        current options for the trim_options dictionary are listed here.\n",
    "        {\"az\" : az_limit} means that if at two timesteps the azimuth\n",
    "        difference in degrees is greater than az_limit, then the line\n",
    "        segment will be trimmed.\n",
    "        {\"az_and_el\" : (az_limit,el_limit)} means that if at two\n",
    "        timesteps the azimuth difference in degrees is greater than\n",
    "        az_limit as well as the average of the elevation angle across\n",
    "        the two timesteps is less than el_limit in degrees, then the\n",
    "        line segment will be trimmed. The el_limit is because satellites\n",
    "        near 90 degrees elevation can traverse large amounts of degrees\n",
    "        in azimuth in a valid trajectory but at low elevations should\n",
    "        not have such large azimuth changes quickly.\n",
    "        {\"gps_millis\",gps_millis_limit} means that line segments will be\n",
    "        trimmed if the milliseconds between the two points is larger\n",
    "        than the gps_millis_limit. This option only works if the\n",
    "        gps_millis row is included in the ``navdata`` variable input.\n",
    "        Default options for the trim options are :code:`\"az_and_el\" : (15.,30.)`\n",
    "        and :code:`\"gps_millis\" : 3.6E6`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.pyplot.figure\n",
    "        Figure object of skyplot.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(navdata,NavData):\n",
    "        raise TypeError(\"first arg to plot_skyplot \"\\\n",
    "                          + \"must be a NavData object.\")\n",
    "\n",
    "    if not isinstance(prefix, str):\n",
    "        raise TypeError(\"Prefix must be a string.\")\n",
    "\n",
    "    # add elevation and azimuth data.\n",
    "    # add_el_az(navdata, receiver_state, inplace=True)\n",
    "\n",
    "    # create new figure\n",
    "    fig = plt.figure(figsize=(6,4.5))\n",
    "    axes = fig.add_subplot(111, projection='polar')\n",
    "\n",
    "    navdata = navdata.copy()\n",
    "    navdata[\"az_sv_rad\"] = np.radians(navdata[\"az_sv_deg\"])\n",
    "    # remove SVs below horizon\n",
    "    navdata = navdata.where(\"el_sv_deg\",0,\"geq\")\n",
    "    # remove np.nan values caused by potentially faulty data\n",
    "    navdata = navdata.where(\"az_sv_rad\",np.nan,\"neq\")\n",
    "    navdata = navdata.where(\"el_sv_deg\",np.nan,\"neq\")\n",
    "\n",
    "    for c_idx, constellation in enumerate(sort_gnss_ids(np.unique(navdata[\"gnss_id\"]))):\n",
    "        const_subset = navdata.where(\"gnss_id\",constellation)\n",
    "        color = \"C\" + str(c_idx % len(STANFORD_COLORS))\n",
    "        cmap = new_cmap(to_rgb(color))\n",
    "        marker = MARKERS[c_idx % len(MARKERS)]\n",
    "        const_label_created = False\n",
    "\n",
    "        # iterate through each satellite\n",
    "        for sv_name in np.unique(const_subset[\"sv_id\"]):\n",
    "            sv_subset = const_subset.where(\"sv_id\",sv_name)\n",
    "\n",
    "            # only plot ~ 50 points for each sat to decrease time\n",
    "            # it takes to plot these line collections if step == \"auto\"\n",
    "            if isinstance(step,str) and step == \"auto\":\n",
    "                step = max(1,int(len(sv_subset)/50.))\n",
    "            elif isinstance(step, int):\n",
    "                step = max(1,step)\n",
    "            else:\n",
    "                raise TypeError(\"step varaible must be 'auto' or int\")\n",
    "            points = np.array([np.atleast_1d(sv_subset[\"az_sv_rad\"])[::step],\n",
    "                               np.atleast_1d(sv_subset[\"el_sv_deg\"])[::step]]).T\n",
    "            points = np.reshape(points,(-1, 1, 2))\n",
    "            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "            norm = plt.Normalize(0,len(segments))\n",
    "\n",
    "            if trim_options is None:\n",
    "                trim_options = {\n",
    "                                \"az_and_el\" : (15.,30.),\n",
    "                                \"gps_millis\" : 3.6E6,\n",
    "                                }\n",
    "            plotted_idxs = np.array([True] * len(segments))\n",
    "\n",
    "            if \"az\" in trim_options and len(segments) > 2:\n",
    "                # ignore segments that cross more than az_limit degrees\n",
    "                # in azimuth between timesteps\n",
    "                az_limit = np.radians(trim_options[\"az\"])\n",
    "                az_idxs = ~((np.abs(np.diff(np.unwrap(segments[:,:,0]))) >= az_limit)[:,0])\n",
    "                plotted_idxs = np.bitwise_and(plotted_idxs, az_idxs)\n",
    "            if \"az_and_el\" in trim_options and len(segments) > 2:\n",
    "                # ignore segments that cross more than az_limit degrees\n",
    "                # in azimuth between timesteps and are at an elevation\n",
    "                # less than el_limit degrees.\n",
    "                # These satellites are assumed to be the satellites\n",
    "                # coming in and out of view in a later part of the orbit\n",
    "                az_limit = np.radians(trim_options[\"az_and_el\"][0])\n",
    "                el_limit = trim_options[\"az_and_el\"][1]\n",
    "                az_and_el_idxs = ~(((np.abs(np.diff(np.unwrap(segments[:,:,0]))) >= az_limit)[:,0]) \\\n",
    "                                 & (np.mean(segments[:,:,1],axis=1) <= el_limit))\n",
    "                plotted_idxs = np.bitwise_and(plotted_idxs, az_and_el_idxs)\n",
    "            if \"gps_millis\" in trim_options and \"gps_millis\" in sv_subset.rows \\\n",
    "                and len(segments) > 2:\n",
    "                # ignore segments if there is more than gps_millis_limit\n",
    "                # milliseconds between the time segments\n",
    "                gps_millis_limit = trim_options[\"gps_millis\"]\n",
    "\n",
    "                all_times = np.atleast_2d(sv_subset[\"gps_millis\"][::step]).T\n",
    "                point_times = np.concatenate([all_times[:-1],all_times[1:]],\n",
    "                                              axis=1)\n",
    "                gps_millis_idxs = (np.abs(np.diff(point_times)) <= gps_millis_limit)[:,0]\n",
    "                plotted_idxs = np.bitwise_and(plotted_idxs, gps_millis_idxs)\n",
    "\n",
    "            segments = segments[list(plotted_idxs)]\n",
    "\n",
    "            local_coord = LineCollection(segments, cmap=cmap,\n",
    "                            norm=norm, linewidths=(4,),\n",
    "                            array = range(len(segments)))\n",
    "            axes.add_collection(local_coord)\n",
    "            if not const_label_created:\n",
    "                # plot with label\n",
    "                axes.plot(np.atleast_1d(sv_subset[\"az_sv_rad\"])[-1],\n",
    "                          np.atleast_1d(sv_subset[\"el_sv_deg\"])[-1],\n",
    "                          c=color, marker=marker, markersize=8,\n",
    "                    label=get_label({\"gnss_id\":constellation}))\n",
    "                const_label_created = True\n",
    "            else:\n",
    "                # plot without label\n",
    "                axes.plot(np.atleast_1d(sv_subset[\"az_sv_rad\"])[-1],\n",
    "                          np.atleast_1d(sv_subset[\"el_sv_deg\"])[-1],\n",
    "                          c=color, marker=marker, markersize=8)\n",
    "            if add_sv_id_label:\n",
    "                # offsets move label to the right of marker\n",
    "                az_offset = 3.*np.radians(np.cos(np.atleast_1d(sv_subset[\"az_sv_rad\"])[-1]))\n",
    "                el_offset = -3.*np.sin(np.atleast_1d(sv_subset[\"az_sv_rad\"])[-1])\n",
    "                axes.text(np.atleast_1d(sv_subset[\"az_sv_rad\"])[-1] \\\n",
    "                          + az_offset,\n",
    "                          np.atleast_1d(sv_subset[\"el_sv_deg\"])[-1] \\\n",
    "                          + el_offset,\n",
    "                          str(int(sv_name)),\n",
    "                          )\n",
    "\n",
    "    # updated axes for skyplot graph specifics\n",
    "    axes.set_theta_zero_location('N')\n",
    "    axes.set_theta_direction(-1)\n",
    "    axes.set_yticks(range(0, 60+10, 30))    # Define the yticks\n",
    "    axes.set_yticklabels(['',r'$30\\degree$',r'$60\\degree$'])\n",
    "    axes.set_ylim(90,0)\n",
    "\n",
    "    handles, _ = axes.get_legend_handles_labels()\n",
    "    if len(handles) > 0:\n",
    "        axes.legend(loc=\"upper left\", bbox_to_anchor=(1.05, 1),\n",
    "                   title=get_label({\"constellation\":\"constellation\"}))\n",
    "\n",
    "    fig.set_layout_engine(layout='tight')\n",
    "\n",
    "    if save: # pragma: no cover\n",
    "        save_figure(fig, \"skyplot\", prefix=prefix, fnames=fname)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glp.plot_skyplot()\n",
    "fig = plot_skyplot(nav_sat, nav_pvt)\n",
    "\n",
    "fig.savefig(os.path.join(dir_name, \"skyplot.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between DOP, CN/0, Covariance, hAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_cov = glp.NavData(csv_path=os.path.join(dir_name, \"NAV_COV.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_cov[\"cov_horiz_rmse\"] = np.sqrt(nav_cov[\"posCovNN\"] + nav_cov[\"posCovEE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may take a few minutes\n",
    "full_cn0_avg = []\n",
    "for timestamp, _, subset in glp.loop_time(nav_sat_used,\"gps_millis\"):\n",
    "    cn0 = subset[\"cn0_dbhz\"]\n",
    "    full_cn0_avg.append(np.mean(cn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(nav_pvt[\"hAcc\"]/1000,nav_dop[\"hDOP\"],'o',markersize=1)\n",
    "plt.xlabel(\"Horizontal Accuracy Estimate [m]\")\n",
    "plt.ylabel(\"hDOP\")\n",
    "plt.ylim(0,5)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(os.path.join(dir_name, \"hAcc_vs_hDOP.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(nav_pvt[\"hAcc\"]/1000,full_cn0_avg,'o',markersize=1)\n",
    "plt.xlabel(\"Horizontal Accuracy Estimate [m]\")\n",
    "plt.ylabel(\"C/N0 [dB-Hz]\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(os.path.join(dir_name, \"hAcc_vs_cn0.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(nav_pvt[\"hAcc\"]/1000,nav_cov[\"cov_horiz_rmse\"],'o',markersize=1)\n",
    "plt.xlabel(\"Horizontal Accuracy Estimate [m]\")\n",
    "plt.ylabel(\"Horizontal Covariance RMSE √(cov_nn + cov_ee) [m]\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(os.path.join(dir_name, \"hAcc_vs_cov_horiz_rmse.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
